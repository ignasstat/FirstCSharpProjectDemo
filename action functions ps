<############################################################################################################################################
   Function Definitions
 
   Created 2019-11-21 - KT - Created from existing template just to house functions
   Updated 2019-11-26 - KT - Added : Get-ExcelRowCount, Get-SQLScalar, gzip-files & WinZip
   Updated 2020-03-13 - GJ - Converted OutputCheck.exe to PS code and added as function
   Updated 2021-11-19 - KT - TOT 391.  Need to include 7zip which is default, Zip-File function now determines the method and calls new 
                             functions to do the actual zipping
                             Added New Function GetClientName to retrieve client name from Neptune for a given Job Number
   Updated 2022-07-21 - KT - TOT 465 - Updated 7Zip parameters to use faster compression
   Updated 2022-10-12 - KT - TOT 465 :
                             Added   - Get-SampleFilename  - Derive a standard name for a sample of any file    
                             Added   - Check-OutputFile    - Perform checks on a files consistency
                             Added   - Parse-CSV           - Accurately parse delimited data
                             Added   - Create-DummyHeader  - Create a dummy header for a delimiter file
                             Updated - Write-DeliveryLog to add further file details generated by Check-OutputFile
   Updated 2022-11-01 - KT - TOT 508 - Updated Write-DeliveryLog to only output standard zip name if there is one
   Updated 2022-11-30 - KT - TOT 514 - Updated Zip-File and 7Zip-File functions so can use either of 7z and 7za
   Updated 2023-07-05 - KT - TOT 560 - Added Check-UniqueID based on Check-OutputFile with addition of checking for unique IDs
   Updated 2023-07-08 - KT - TOT 530 - 4 new functions to support Report Downloading
                                Get-JobID 
                                Get-CobraSQLConfig
                                Get-CobraTextConfig
                                Get-ReportFiles
   Updated 2023-07-11 - KT - TOT 530 - 2 minor amendments
                                If re-running script after reports have already been copied, then can continue 
                                Add optional parameter for JobID so calling script can specify which to use when this isn't the latest run
   Updated 2023-10-03 - KT - TOT 590 - minor amendments to the function Get-ReportFiles
                                If JobId isn't supplied and can't be found then report this and quit with failure
   Updated 2023-12-10 - KT - CBC 076 - Added function to dodwnload statistics Get-StatsFile 
   Updated 2024-01-26 - KT - TOT 615 - Fixed Write-DeliveryLog was using filename spec instead of actual value from Record Counts collection
   Updated 2024-02-03 - KT - TOT 615 - Added Function Get-FixedLengthRowCount 
   Updated 2024-02-06 - KT - TOT 615 - Fixed bug in Function Write-DeliveryLog. For multiple Output Files it wasn't creating seperate entries in the log
   Updated 2024-02-25 - KT - TOT 613 - Added parameter to Get-ReportFiles - UseBIReport - Overrides default client report for TV Repeats
   Updated 2024-03-07 - KT - TOT 626 - Need to pass OutputSubfolder as a parameter to Get-ReportFiles
   Updated 2024-04-05 - KT - TOT 632 - Updated the 3 zip functions (zip-file, 7zip-file, winzip-file) to allow an optional parameter for removing original files
   Updated 2024-04-10 - KT - TOT 638 - Revised the function get-JobId to account for timing delays on completing the BWF jobs.
      
############################################################################################################################################>

# Function generates [[FileName]].OutputCheck file. Checks for errors
function Start-OutputCheck {
    param ([string]$SourceFilePath, $BlockSize, $LogFile)
    #$SourceFilePath = "\\cig.local\data\AppData\SFTP\Data\Usr\DataBureau\Test\DataDNA post processing\CDA104315_202003_Cobra.bsb.csv"

    [int]$DefaultBlockSize = 10000
    [int]$MaxBlockSize = 1048576
    [int]$MinBlockSize = 1

    try {
        if ($null -eq $SourceFilePath) {
            throw "No file path parameter has been provided."
        }

        if ($null -eq $BlockSize) {
            $BlockSize = $DefaultBlockSize
        }

        $SampleFilePath = "$SourceFilePath`.OutputCheck"
        [string]$str = ""
        #[byte[$BlockSize]]$numArray = new-object byte $BlockSize

        $numArray = [System.Byte[]]::CreateInstance([System.Byte], $BlockSize)

        if (($BlockSize -gt $MaxBlockSize) -or ($BlockSize -lt $MinBlockSize)) {
            throw "Invalid block size. Block size must be between $MinBlockSize and $MaxBlockSize"
        }

        if (!(Test-path $SourceFilePath)) {
            throw "Could not find file $SourceFilePath"
        }

        if (([System.IO.FileInfo]$SourceFilePath).Length -lt ($BlockSize * 2)) {
            throw "File size is less than twice the block size. Output check is redundant."
        }

        $SourceFile = new-object System.IO.FileStream $SourceFilePath, 'Open'
        $SampleFile = new-object System.IO.FileStream $SampleFilePath, 'Create'

        $UTF8Encoding = [System.Text.Encoding]::UTF8
        $SourceFile.Read($numArray, 0, $BlockSize)
        $str = $UTF8Encoding.GetString($numArray)
        $SampleFile.Write($UTF8Encoding.GetBytes($str), 0, $str.Length)
        $str = "\r\n";

        for ([int]$i = 0; $i -lt 100; $i++) {
            $str = [string]::Concat($str, "-")
        }

        $str = [string]::Concat($str, "\r\n")
        $SampleFile.Write($UTF8Encoding.GetBytes($str), 0, $str.Length)

        $str = ""
        $SourceFile.Seek(-$BlockSize, 'End')
        $SourceFile.Read($numArray, 0, $BlockSize)

        $str = $UTF8Encoding.GetString($numArray)
        $SampleFile.Write($UTF8Encoding.GetBytes($str), 0, $str.Length)

        $SourceFile.Close()
        $SampleFile.Close()
        $SourceFile.Dispose()
        $SampleFile.Dispose()

        Return 0
        #Exit 0
    }
    catch { #(Exception exception)
        Write-Log $LogFile $_
        if ($null -ne $SourceFile) {
            $SourceFile.Dispose();
        }

        if ($null -ne $SampleFile) {
            $SampleFile.Dispose();
        }
        #Exit 1
        Return 1
    }
}

# Audit function
function Write-Log-Old {
    Param(  [String] $AuditLogFile,
            [String] $AuditMessage,
            $ErrorFound )

    $MyDate = get-date

    [string]$FullMessage = $MyDate.ToLongDateString() + "|" + $MyDate.ToLongTimeString() + "|" + $AuditMessage

    if($ErrorFound) {
        write-Host  $AuditMessage -ForegroundColor Red
    }
    else {
        write-Host  $AuditMessage -ForegroundColor White
    }

    Add-Content $AuditLogFile ($FullMessage)
}

# Audit function - Updated to include retries
function Write-Log {
    Param(  [String] $AuditLogFile,
            [String] $AuditMessage,
            $ErrorFound )

    $MyDate = get-date

    [string]$FullMessage = $MyDate.ToLongDateString() + "|" + $MyDate.ToLongTimeString() + "|" + $AuditMessage

    if($ErrorFound) {
        write-Host  $AuditMessage -ForegroundColor Red
    }
    else {
        write-Host  $AuditMessage -ForegroundColor White
    }

    # can get hung up due to network latency - so include retry
    $MaxTries = 10
    while( !$Completed) {
        try {
            Add-Content $AuditLogFile ($FullMessage) -erroraction Stop
            $Completed = $True
        }
        catch {
            Start-Sleep -Seconds 2
            $MaxTries -= 1
        }
        if( $MaxTries -lt 0 ){ 
            write-host "Failed to write to log: $FullMessage" 
            $Completed = $True
        }
    }
}

# ----------------------------------------------------------------------------------------------------------------------------------------------
# Create folders tidily
function Create-Folder {
    Param (
            [string]$FolderName,
            [string]$AuditLog )

    $Result = $True

    if(!(test-path $FolderName)) {
        try {
            New-item $FolderName -ItemType Directory -ErrorAction Stop |out-null
            Write-Log $AuditLog "Created Folder $FolderName"
        }
        catch {
            Write-Log $AuditLog "Failed to Create Folder $FolderName"  -ErrorFound $True
            $Result = $False
        }
    }
    else {
        Write-Log $AuditLog "Folder Exists $FolderName"
    }
    return $Result
}
# ----------------------------------------------------------------------------------------------------------------------------------------------
# Remove Files
function Remove-Files {
    Param ( [string]$FileSpec, [string]$AuditLog )

    $Files = $(Get-ChildItem $FileSpec -File).FullName

    foreach( $File in $Files) {
        try {
            Remove-Item $File -ErrorAction stop
            Write-Log $AuditLog "Deleted file: $File"
        }
        catch {
            Write-Log $AuditLog "Failed to delete file: $File" -ErrorFound $True
        }
    }
}
# ----------------------------------------------------------------------------------------------------------------------------------------------
# Copy Files
function Copy-Files {
    Param ( [string]$SourceFileSpec, [string]$Destination, [string]$AuditLog )


    # check the source is valid
    if(test-path $SourceFileSpec) {

        # create target folder if it doesn't exist
        if((Create-Folder -FolderName $Destination -AuditLog $AuditLog)) {

            # get individual files to copy
            $FileList = $(Get-ChildItem $SourceFileSpec -File).FullName

            # go through each file in turn
            foreach($File in $FileList) {
                Try {
                    Copy-Item -Path $File -Destination $Destination -ErrorAction Stop |out-null
                    Write-Log $AuditLog "Copied File: $File"
                    Write-Log $AuditLog "Copied To  : $Destination"
                }
                Catch {
                    Write-Log $AuditLog "Failed to Copy File: $File" -ErrorFound $True
                    Write-Log $AuditLog "Copying to         : $Destination" -ErrorFound $True
                }
            }
        }
        else {
            Write-Log $AuditLog "Failed to Create Destination Folder: $Destination" -ErrorFound $True
        }
    }
    else {
        Write-Log $AuditLog "Failed to Find File to Copy for: $SourceFileSpec" -ErrorFound $True
    }
}
# ----------------------------------------------------------------------------------------------------------------------------------------------
# Move Files
function Move-Files {
    Param ( [string]$SourceFileSpec, [string]$Destination, [string]$AuditLog )

    # check the source is valid
    if(test-path $SourceFileSpec) {

        # create target folder if it doesn't exist
        if((Create-Folder -FolderName $Destination -AuditLog $AuditLog)) {

            # get individual files to Move
            $FileList = $(Get-ChildItem $SourceFileSpec -File).FullName

            # go through each file in turn
            foreach($File in $FileList) {
                Try {
                    Move-Item -Path $File -Destination $(join-path $Destination $File.Name) -ErrorAction Stop |out-null
                    Write-Log $AuditLog "Moved File: $File"
                    Write-Log $AuditLog "Moved To  : $Destination"
                }
                Catch {
                    Write-Log $AuditLog "Failed to Move File: $File" -ErrorFound $True
                    Write-Log $AuditLog "Moving to          : $Destination" -ErrorFound $True
                }
            }
        }
        else {
            Write-Log $AuditLog "Failed to Create Destination Folder: $Destination" -ErrorFound $True
        }
    }
    else {
        Write-Log $AuditLog "Failed to Find File to Move for: $SourceFileSpec" -ErrorFound $True
    }
}
# ----------------------------------------------------------------------------------------------------------------------------------------------
# Rename File
function Rename-File {
    Param ( [string]$SourceFile, [string]$NewName, [string]$AuditLog )

    # check the source is valid
    if(test-path $SourceFile) {

        # get individual files to Move
        if((Get-ChildItem $SourceFile -File).count -gt 1) {
            Write-Log $AuditLog "Failed to Rename - Multiple Files Found: $SourceFile" -ErrorFound $True
        }
        else {
            Try {
                Rename-Item -Path $SourceFile -NewName $NewName -ErrorAction Stop |out-null
                Write-Log $AuditLog "Renamed File: $SourceFile"
                Write-Log $AuditLog "Renamed To  : $NewName"
            }
            Catch {
                Write-Log $AuditLog "Failed to Rename File: $SourceFile"    -ErrorFound $True
                Write-Log $AuditLog "Renaming to          : $NewName" -ErrorFound $True
            }
        }
    }
    else {
        Write-Log $AuditLog "Failed to Find File to Rename for: $SourceFile" -ErrorFound $True
    }
}
# ----------------------------------------------------------------------------------------------------------------------------------------------
# Audit function
function SearchFile {
                    Param(  $TargetFile,
                            $WordSearch,
                            $LogFile    )

    Write-Log $LogFile "Checking File $TargetFile" $False
    $LineCount=0

    if(test-path $TargetFile) {
        Try {
            $FileContent = Get-Content $TargetFile

            foreach($Line in $FileContent) {

                $LineCount++
                $LineError=0

                foreach($Word in $WordSearch) {
                    if( $Line.IndexOf($Word.word) -gt 0) {
                        $Word.count++
                        $LineError++
                    }
                }
                if($LineError -gt 0) {
                    Write-Log $LogFile "ErrorFound: $Line" $True
                }
            }
            Write-Log $LogFile "Search Complete"
            foreach($Word in $WordSearch) {
                Write-Log $LogFile "Matches Found - $($Word.word) `t $($Word.count)"
            }
        }
        Catch {
            Write-Log $LogFile "Error Searching File" $True
        }
    }
    else {
        Write-Log $LogFile "File Not Found" $True
    }
}
# ----------------------------------------------------------------------------------------------------------------------------------------------
#function to zip the files using WinZip Command line - Zips using -rp which is recursive including subfolders
Function Winzip {
    [CmdletBinding()]
     param  (
                [Parameter(Mandatory = $true)] [String] $ZipDestination,
                [Parameter(Mandatory = $true)] [String] $FileToZip,
                [Parameter(Mandatory = $true)] [String] $LogFile
            )

    # Locate WZZIP Command line
    $winzip = "Not Found"
    if(test-path "C:\Program Files\WinZip\WZZIP.EXE") {
        $winzip = "C:\Program Files\WinZip\WZZIP.EXE"
    }
    elseif (test-path "C:\Program Files (x86)\WinZip\WZZIP.EXE") {
        $winzip = "C:\Program Files (x86)\WinZip\WZZIP.EXE"
    }

    if($winzip -eq "Not Found") {
        Write-Log $LogFile "Failed - Unable to locate WZZIP Command Line" $True
    }
    else {
        # execute wzzip command - need quotes around parametrs in case of spaces
        $Params = "-rp `"$ZipDestination`" `"$FileToZip`""

        try {
            Start-Process -filepath "$winzip" -ArgumentList "$Params" -Wait -ErrorAction stop
            Write-Log $LogFile "Zipped Files - $FileToZip"
        }
        catch {
            Write-Log $LogFile "Failed - Zipping Files - $FileToZip" $True
        }
    }
}

# ----------------------------------------------------------------------------------------------------------------------------------------------
# function to zip the files using WinZip Command line - Zips using using default parameters so doesn't recurse folders
# TOT 391 - Need to allow for 7Zip as priority, so change this function to be generic and create two new functions (7Zip-File & WinZip-File) for 
# dealing with the two different options.
Function Zip-File {
    [CmdletBinding()]
     param  (
                [Parameter(Mandatory = $true)] [String]  $ZipDestination,
                [Parameter(Mandatory = $true)] [String]  $FileToZip,
                [Parameter(Mandatory = $true)] [String]  $LogFile,
                [Parameter(Mandatory = $false)][Boolean] $RemoveOriginalFile=$False
            )

    Write-Log $LogFile "Starting Zip for - $FileToZip" $False
    
    # Locate ZIP Command line
    # # TOT 514 - Changed to there is a list of commands and added both 7z and 7za
    if($(test-path "C:\Program Files\7-Zip\7z.exe") -or $(test-path "C:\Program Files (x86)\7-Zip\7z.exe") -or $(test-path "C:\Program Files\7-Zip\7za.exe") -or $(test-path "C:\Program Files (x86)\7-Zip\7za.exe"))  {
        7Zip-File -ZipDestination $ZipDestination -FileToZip $FileToZip -LogFile $LogFile -RemoveOriginalFile $RemoveOriginalFile
    }
    elseif ($(test-path "C:\Program Files\WinZip\WZZIP.EXE") -or $(test-path "C:\Program Files (x86)\WinZip\WZZIP.EXE")) {
        WinZip-File -ZipDestination $ZipDestination -FileToZip $FileToZip -LogFile $LogFile -RemoveOriginalFile $RemoveOriginalFile
    }
    else {
        Write-Log $LogFile "Failed - Unable to locate a Zip Command Line" $True
    }

}
# ----------------------------------------------------------------------------------------------------------------------------------------------

# ----------------------------------------------------------------------------------------------------------------------------------------------
#function to zip the files using WinZip Command line - Zips using using default parameters so doesn't recurse folders
Function WinZip-File {
    [CmdletBinding()]
     param  (
                [Parameter(Mandatory = $true)] [String]  $ZipDestination,
                [Parameter(Mandatory = $true)] [String]  $FileToZip,
                [Parameter(Mandatory = $true)] [String]  $LogFile,
                [Parameter(Mandatory = $false)][Boolean] $RemoveOriginalFile=$False
            )

    # Locate WZZIP Command line
    $winzip = "Not Found"
    if(test-path "C:\Program Files\WinZip\WZZIP.EXE") {
        $winzip = "C:\Program Files\WinZip\WZZIP.EXE"
    }
    elseif (test-path "C:\Program Files (x86)\WinZip\WZZIP.EXE") {
        $winzip = "C:\Program Files (x86)\WinZip\WZZIP.EXE"
    }

    if($winzip -eq "Not Found") {
        Write-Log $LogFile "Failed - Unable to locate WZZIP Command Line" $True
    }
    else {
        # execute wzzip command - need quotes around parametrs in case of spaces
        if($RemoveOriginalFile) {
            $Params = "`"$ZipDestination`" -m `"$FileToZip`""
        }
        else {
            $Params = "`"$ZipDestination`" `"$FileToZip`""
        }

        try {
            Start-Process -filepath "$winzip" -ArgumentList "$Params" -Wait -ErrorAction stop
            Write-Host "-filepath `"$winzip`" -ArgumentList `"$Params`" -Wait -ErrorAction stop"
            Write-Log $LogFile "Win Zipped Files - $FileToZip"
        }
        catch {
            Write-Log $LogFile "Failed - Win Zipping Files - $FileToZip" $True
        }
    }
}
# ----------------------------------------------------------------------------------------------------------------------------------------------
# ----------------------------------------------------------------------------------------------------------------------------------------------
#function to zip the files using 7Zip Command line - Zips using using default parameters so doesn't recurse folders
Function 7Zip-File {
    [CmdletBinding()]
     param  (
                [Parameter(Mandatory = $true)] [String]  $ZipDestination,
                [Parameter(Mandatory = $true)] [String]  $FileToZip,
                [Parameter(Mandatory = $true)] [String]  $LogFile,
                [Parameter(Mandatory = $false)][Boolean] $RemoveOriginalFile=$False
            )

    # Locate 7ZIP Command line, multiple options
    # TOT 514 - Changed so there is a list of commands and added both 7z and 7za
    $Commands = @()
    $Commands += "C:\Program Files\7-Zip\7z.exe"
    $Commands += "C:\Program Files (x86)\7-Zip\7z.exe"
    $Commands += "C:\Program Files\7-Zip\7za.exe"
    $Commands += "C:\Program Files (x86)\7-Zip\7za.exe"

    $7zip = "Not Found"
    foreach( $Command in $Commands) {
        if(test-path $Command) { 
            $7zip = $Command
            break;
        }
    }

    # execute zip command - need quotes around parameters in case of spaces
    # TOT 465 - Update parameters to use faster compression
    if($RemoveOriginalFile) {
        $Params = "a -sdel -mx=1 -mmt=off `"$ZipDestination`" `"$FileToZip`""
    }
    else {
        $Params = "a -mx=1 -mmt=off `"$ZipDestination`" `"$FileToZip`""
    }

    try {
        Start-Process -filepath "$7zip" -ArgumentList $Params  -Wait -ErrorAction stop
        Write-Host   "-filepath `"$7zip`" -ArgumentList $Params`" -Wait -ErrorAction stop"
        Write-Log $LogFile "7 Zipped Files - $FileToZip"
    }
    catch {
        Write-Log $LogFile "Failed - 7 Zipping Files - $FileToZip" $True
    }   
}
# ----------------------------------------------------------------------------------------------------------------------------------------------

#function to execute sql query and return single result record
function Get-SQLScalar {
    [CmdletBinding()]
    param
    (
        [Parameter(Mandatory = $true)] [String] $Query,
        [Parameter(Mandatory = $true)] [String] $ConnectionString
    )

    $Connection = New-Object System.Data.SQLClient.SQLConnection($ConnectionString)
    $Connection.Open()
    $Command = New-Object System.Data.SQLClient.SQLCommand($Query, $Connection)
    $SQLScalar = $Command.ExecuteScalar()
    $Connection.Close()

    return $SQLScalar
}

#function to execute sql query and return a single data set
function Get-SQLDataset {
    [CmdletBinding()]
    param
    (
        [Parameter(Mandatory = $true)] $Query,
        [Parameter(Mandatory = $true)] $ConnectionString
    )

    <# Testing
    $ConnectionString = Get-CobraTextConfig 'MB21' "\\VALWINLVAPP030\bsbappend$\Jobs\Processing\PSScripts\Configuration\SQLConnectionCobraConfig.txt"
    $Query = $(get-content $(join-path $(Get-CobraSQLConfig 'ScriptFolder' $ConnectionString) 'JobMI.sql')).Replace('<JobId>', 36715)
    $ConnectionString = Get-CobraTextConfig 'BWFE' "\\VALWINLVAPP030\bsbappend$\Jobs\Processing\PSScripts\Configuration\SQLConnectionCobraConfig.txt"
    #>

    $Connection = New-Object System.Data.SQLClient.SQLConnection($ConnectionString)
    $Connection.Open()
    
    $Command = New-Object System.Data.SQLClient.SQLCommand($Query, $Connection)
    $Adapter = new-object System.Data.SqlClient.SqlDataAdapter($Command)
    $dataSet = new-object System.Data.Dataset
    $RecordCount = $Adapter.Fill($dataSet) 
    $Data = $dataSet.Tables[0]

    $Connection.Close();

    return $Data
}

# ----------------------------------------------------------------------------------------------------------------------------------------------
# function to count the number of lines in a text file
function Get-RecordCount {
    [CmdletBinding()]
    param
    (
        [Parameter(Mandatory = $true)] [String] $FilePath
    )

    if((test-path $FilePath)) {

        Try {
            $StreamReader = New-Object IO.StreamReader($FilePath)
            $FileCount = 0
            while(($line = $StreamReader.ReadLine()) -ne $null) { $FileCount++ }
            $StreamReader.Close(); $StreamReader.Dispose()
        }
        Catch {
            $FileCount = -1
        }
    }
    else {
        $FileCount = -1
    }

    return $FileCount
}
# ----------------------------------------------------------------------------------------------------------------------------------------------
#  Get Row Count from Excel Monitoring Document
#
#  The script will check the gievn workshete of the given document.  It will read down the first column until it finds a match with the
#  RowHeading, then read across until it finds match with the ColHeading.  The value returned is immediately below this cell.
#
function Get-ExcelRowCount {
    Param ( [string]$ExcelFile, [string]$WorkSheet, [string]$RowHeading, [string]$ColHeading, [string]$LogFile  )

    # set default return value
    $RecordCount = "Not Found"

    # check the source is valid
    if(test-path $ExcelFile) {
        Try{
            # create Excel Object and open workbook
            $Excel=new-object -com excel.application
            $WorkBook=$Excel.workbooks.open($ExcelFile,2,$true)

            # Select the Summary worksheet
            $SummarySheet = $WorkBook.worksheets | where {$_.Name -match $WorkSheet}

            # Find the Rows headed MONTH and TOTAL, which should be consecutive
            for ($i = 1; $i -le 100; $i++) {
                if($SummarySheet.Cells($i,1).value2 -match $RowHeading) {
                    $MonthRow = $i
                    $TotalRow = $i+1
                    break
                }
            }

            # Find the relevant Month Column on the Month row
            if($MonthRow -gt 0) {
                for ($i = 1; $i -le 1000; $i++) {
                    if($SummarySheet.Cells($MonthRow,$i).value2 -eq $ColHeading) {
                        $RecordCount = $SummarySheet.Cells($TotalRow,$i).value2
                        break
                    }
                }
            }
            Write-Log $LogFile "Successfully read information from Excel File: $ExcelFile "

        }
        catch {
            Write-Log $LogFile "Failed to Read information from Excel File: $ExcelFile" -ErrorFound $True
        }

        $WorkBook.Close($false)
        $Excel.Quit()
        Start-Sleep 2
        [System.Runtime.Interopservices.Marshal]::ReleaseComObject($Excel) | Out-Null
        Start-Sleep 2
        Remove-Variable excel
    }
    else {
        Write-Log $LogFile "Failed to Find File to Move for: $ExcelFile" -ErrorFound $True
    }

    return $RecordCount
}
# ----------------------------------------------------------------------------------------------------------------------------------------------
# GZIP - Files
function gzip-Files {
    Param ( [string]$FileSpec, [string]$AuditLog )

    $Files = $(Get-ChildItem $FileSpec -File).FullName

    foreach( $File in $Files) {
        try {
            GZIP $File
            Write-Log $AuditLog "GZipped file: $File"
        }
        catch {
            Write-Log $AuditLog "Failed to GZipped file: $File" -ErrorFound $True
        }
    }
}
# ----------------------------------------------------------------------------------------------------------------------------------------------

# Get the Client Name from Neptune for a Specific Job Number
function GetClientName {
    Param ( [string]$JobNumber)

    [String]$ConnectionString = "Data Source=PLLWINLVSQL002,1433;Integrated Security=SSPI;Initial Catalog=DataBureauDataLoadAudit"
    [String]$ClientNameQuery  = "exec [dbo].[up_COBRA_GetClientName] '$JobNumber'‚Äù
    [String]$Client = get-SQLScalar -Query $ClientNameQuery -ConnectionString $ConnectionString

    return $Client
}
# ----------------------------------------------------------------------------------------------------------------------------------------------
#Testing
#$myClient = GetClientName 'CDA0008597'

# Testing for speed
Function Test-It {
    $FilePath = "\\VALWINLVAPP030\bsbappend$\Jobs\CDA0004622Test\ReformattedFiles\CDA0004622_TrueVision.rfm.csv"

    clear-host
    $FileSize = (Get-Item $FilePath).length
    write-host "File Size = $FileSize"
    #write-host $(get-date)
    #$FileCount = (Get-Content $FilePath).count
    #write-host "Quick Method = $FileCount"
    write-host $(get-date)
    $StreamReader = New-Object IO.StreamReader($FilePath)
    $FileCount = 0
    while(($line = $StreamReader.ReadLine()) -ne $null) {$FileCount++}
    $StreamReader.Close()
    $StreamReader.Dispose()
    write-host "Slow Method = $FileCount"
    write-host $(get-date)
}
# ----------------------------------------------------------------------------------------------------------------------------------------------

Function Write-DeliveryLog_Old {
    Param ( $ConfigList, $RecordCounts, $DeliveryLogFile)

    # overwrite existing log
    remove-item $DeliveryLogFile -Force -ErrorAction silentlycontinue
 
    # Write away basic information
    Add-content $DeliveryLogFile ("DeliveryLogVersion|2.00")
    Add-content $DeliveryLogFile ("JobType|$(GetConfigValue $ConfigList 'JobType')")
    Add-content $DeliveryLogFile ("ClientName|$(GetConfigValue $ConfigList 'ClientName')")
    Add-content $DeliveryLogFile ("StandardDelivery|$(GetConfigValue $ConfigList 'StandardDelivery')")
    Add-content $DeliveryLogFile ("RawDelivery|$(GetConfigValue $ConfigList 'RawDelivery')")
    Add-content $DeliveryLogFile ("CobraShareFolder|$(GetConfigValue $ConfigList 'FullCobraShareFolder')")
    
    # Delivery folder depends on options selected
    if( ($(GetConfigValue $ConfigList 'StandardDelivery') -eq 'Client') -or ($(GetConfigValue $ConfigList 'RawDelivery') -eq 'Client') ) {
        Add-content $DeliveryLogFile ("DeliveryFolder|$(GetConfigValue $ConfigList 'DeliveryFolder')")
    }
    else {
        Add-content $DeliveryLogFile ("DeliveryFolder|Not Applicable - Internal Only")
    }
    
    # Standard Zip and its contents
    Add-content $DeliveryLogFile ("StandardOutputZip|$(GetConfigValue $ConfigList "StandardOutputZip")")

    foreach($OutputFile in $(GetConfigValue $ConfigList "OutputFileName") ) {
        Add-content $DeliveryLogFile ("OutputFile|$OutputFile|$($($RecordCounts| where { $_.Name -like "*$($OutputFile)" } ).count)")
    }

    # Raw Zip and its contents - If Required
    if($(GetConfigValue $ConfigList "RawOutputFilename")) {
        Add-content $DeliveryLogFile ("RawOutputZip|$(GetConfigValue $ConfigList "RawOutputZip")")

        foreach($OutputFile in $(GetConfigValue $ConfigList "RawOutputFileName") ) {
            Add-content $DeliveryLogFile ("OutputFile|$OutputFile|$($($RecordCounts| where { $_.Name -like "*$OutputFile" } ).count)")
        }
    }
}

Function Write-DeliveryLog {
    Param ( $ConfigList, $RecordCounts, $DeliveryLogFile)
    # 2022-10-12 - KT - Updated to include further file details, for use in the new check list
    # 2022-11-01 - KT - Only output standard zip name if there is one

    # overwrite existing log
    remove-item $DeliveryLogFile -Force -ErrorAction silentlycontinue
 
    # Write away basic information
    Add-content $DeliveryLogFile ("DeliveryLogVersion|2.10")
    Add-content $DeliveryLogFile ("JobType|$(GetConfigValue $ConfigList 'JobType')")
    Add-content $DeliveryLogFile ("ClientName|$(GetConfigValue $ConfigList 'ClientName')")
    Add-content $DeliveryLogFile ("StandardDelivery|$(GetConfigValue $ConfigList 'StandardDelivery')")
    Add-content $DeliveryLogFile ("RawDelivery|$(GetConfigValue $ConfigList 'RawDelivery')")
    Add-content $DeliveryLogFile ("CobraShareFolder|$(GetConfigValue $ConfigList 'FullCobraShareFolder')")
    
    # Delivery folder depends on options selected
    if( ($(GetConfigValue $ConfigList 'StandardDelivery') -eq 'Client') -or ($(GetConfigValue $ConfigList 'RawDelivery') -eq 'Client') ) {
        Add-content $DeliveryLogFile ("DeliveryFolder|$(GetConfigValue $ConfigList 'DeliveryFolder')")
    }
    else {
        Add-content $DeliveryLogFile ("DeliveryFolder|Not Applicable - Internal Only")
    }
    
    # Standard Zip 
    if($(GetConfigValue $ConfigList "StandardOutputZip")) {
        Add-content $DeliveryLogFile ("StandardOutputZip|$(GetConfigValue $ConfigList "StandardOutputZip")")
    }
    else {
        Add-content $DeliveryLogFile ("StandardOutputZip|Not Applicable")
    }

    # Standard Output - or all output if zipped individually
    foreach($OutputFile in $(GetConfigValue $ConfigList "OutputFileName") ) {
               
        # TOT 615 find the related information in the RecordCounts collection
        $FileDetails = $($RecordCounts| where { $_.Name -like "*$($OutputFile)" })
        
        # TOT 615 put this in a loop
        Foreach($FileDetail in $FileDetails) {
            Add-content $DeliveryLogFile ("OutputFile|$($FileDetail.Name)|$($FileDetail.count)|$($FileDetail.HeaderRecord)|$($FileDetail.ColumnCount)|$($FileDetail.RecordLength)|$($FileDetail.NullsFound)")
        }
    }

    # Raw Zip and its contents - If Required
    if($(GetConfigValue $ConfigList "RawOutputFilename")) {
        Add-content $DeliveryLogFile ("RawOutputZip|$(GetConfigValue $ConfigList "RawOutputZip")")

        foreach($OutputFile in $(GetConfigValue $ConfigList "RawOutputFileName") ) {
            
            # TOT 615 find the related information in the RecordCounts collection
            $FileDetails = $($RecordCounts| where { $_.Name -like "*$($OutputFile)" })
            
            # TOT 615 put this in a loop
            Foreach($FileDetail in $FileDetails) {
                Add-content $DeliveryLogFile ("OutputFile|$($FileDetail.Name)|$($FileDetail.count)|$($FileDetail.HeaderRecord)|$($FileDetail.ColumnCount)|$($FileDetail.RecordLength)|$($FileDetail.NullsFound)")
            }
        }
    }

}

Function Check-OutputFiles {
	param
	(
		[String]$FilePath,
		[Boolean]$Delimited=$True,
		[String]$Delimiter=','
	)

<# testing
		[String]$FilePath="\\VALWINLVAPP030\bsbappend$\Jobs\TEST_AREA\KT_20220906\CDATest_TrueVision.csv"
        $SampleFile = "\\VALWINLVAPP030\bsbappend$\Jobs\TEST_AREA\KT_20220906\CDATest_TrueVision_Temp.csv"
		[Boolean]$Delimited=$True
		[String]$Delimiter=','
#>

	if (Test-Path -LiteralPath $FilePath) 
	{
		#$UTF8_StreamReader = New-Object System.IO.StreamReader ($FilePath, $UTF8_Encoding, $TRUE)
		$Windows_Encoding  = [System.Text.Encoding]::GetEncoding("Windows-1252")
		$StreamReader      = New-Object System.IO.StreamReader ($FilePath, $Windows_Encoding, $TRUE)
		$FirstLine = $StreamReader.ReadLine()
        
        # need to check the column counts for the first and last records both match to the header record
        # easiest way is to create a temporary file 
        
        if( $FirstLine.contains("App1URN") ) {
            # have a header row
            Get-Content $FilePath -TotalCount 2 | Out-File $SampleFile
            
            $MyData = import-csv -LiteralPath $SampleFile -Delimiter $Delimiter -Header 1
            $MyData.Count
        }

        # go to a position from the end which will ensure we cover the entire last line
        $OffSet = $StreamReader.BaseStream.Length - ($FirstLine.Length * 2)
		if ($OffSet -lt 1) { 
            # Very small file, so just read through it
            $OffSet = 1 
        }
		
        # Read through a line at a time until we get the last line
		$StreamReader.BaseStream.Seek($offset, [System.IO.SeekOrigin]::Begin) | out-null
		while (!($StreamReader.EndOfStream)) {
			$filedata = $StreamReader.ReadLine()
			# Interate to see last line
			if ($StreamReader.Peek() -eq -1) 
			{
				$LastLine = $filedata
			}
		}   
		$StreamReader.Close()
		$StreamReader.Dispose()

    	# check can read data and it doesn't contain Null characters    
		If (([string]::IsNullOrEmpty($FirstLine)) -or ([string]::IsNullOrEmpty($LastLine))) {
			$ReadOk = $False
        } else {
            $ReadOK = $True
            
            If (($FirstLine.Contains([char]$Null)) -or ($LastLine.Contains([char]$Null))) {
                $NullsFound = $True 		
            } else {
                $NullsFound = $False
            }
        }

        if($ReadOK -and !$NullsFound) {

		    if ($Delimited) {
			    #  Check number of delimiters in first and last records (excluding those which are text qualified), this number should match and should be above the ExpectedDelimiterCount parameter.
                # If Expected delimiter count is 0 that indicates we don't know what it is and just need to check first and last are the same.

                # Create a dummy header record with more columns than we need
                if($ExpectedDelimiterCount -gt 0 ){
                    $DummyHeaderColumns = $ExpectedDelimiterCount+5
                } else {
                    $DummyHeaderColumns = [regex]::matches($FirstLine, $Delimiter).count + 5
                }
                
                $DummyHeader = @()
                For ($i = 1; $i -le $DummyHeaderColumns; $i++) {
                    $DummyHeader += "Col$i"
                }
           
                $FirstLineAsCSV    = ConvertFrom-Csv $FirstLine -Delimiter $Delimiter -Header $DummyHeader
                $Templine    = ConvertFrom-Csv $FirstLine -Delimiter $Delimiter -Header $DummyHeader
                
                $StrippedFirstLine = $FirstLine
                For ($y = 1; $y -lt $i; $y++) {
                    try { $StrippedFirstLine = $StrippedFirstLine.Replace("$($FirstLineAsCSV.$("Col$y"))","") } Catch {} 
                }
                $FirstLineDelimiterCount = $StrippedFirstLine.Split($Delimiter).Count-1
			    
                If( $FirstLineDelimiterCount -lt $ExpectedDelimiterCount ) {
				    #-4 Not Enough Delimiters (when there should be)
				    Write-Host "[$(get-date -format "HH:mm:ss")] Not Enough Delimiters in First Record"
				    Return (-4)
			    }
            
                $LastLineAsCSV    = ConvertFrom-Csv $LastLine -Delimiter $Delimiter -Header $DummyHeader
                $StrippedLastLine = $LastLine
                For ($y = 1; $y -lt $i; $y++) {
                    try { $StrippedLastLine = $StrippedLastLine.Replace("$($LastLineAsCSV.$("Col$y"))","") } Catch {} 
                }
                $LastLineDelimiterCount = $StrippedLastLine.Split($Delimiter).Count-1

			    If( $LastLineDelimiterCount -lt $ExpectedDelimiterCount ) {
				    #-4 Not Enough Delimiters (when there should be)
				    Write-Host "[$(get-date -format "HH:mm:ss")] Not Enough Delimiters in Last Record"
				    Return (-4)
			    }

			    # Check first and last record lengths. They should match.
			    If( $FirstLineDelimiterCount -ne $LastLineDelimiterCount ) {
				    #-5 Unequal Delimiter Count (when there should be)
				    Write-Host "[$(get-date -format "HH:mm:ss")] Unequal Delimiter Count"
				    Return (-5)
			    }
			
			    # Count number of records
			    $retrycount = 0
			    $completed = $false
			    $secondsDelay = 3
			    $retries = 5

			    while (-not $completed) {
				    try {
					    $RecordCount = [Linq.Enumerable]::Count([System.IO.File]::ReadLines($FilePath))
					
					    $completed = $true
				    } catch {
					    if ($retrycount -ge $retries) {
						    Write-Host "[$(get-date -format "HH:mm:ss")] Failed the maximum number of $retrycount times"
						    $completed = $true
					    } else {
						    Write-Host "[$(get-date -format "HH:mm:ss")] Failed. Retrying in $secondsDelay seconds"
						    Start-Sleep $secondsDelay
						    $retrycount++
					    }
				    }
			    }
			
			    Return $RecordCount
		    }
		    else {
			    # Check first and last record lengths. They should match.
			    If( $FirstLine.Length -ne $LastLine.Length ) {
				    #-3 Not Fixed Length (when it should be)
				    Write-Host "[$(get-date -format "HH:mm:ss")] Not A Fixed Length File"
				    Return (-3)
			    }
			
			    $FileSize = ([System.IO.FileInfo]$FilePath).Length
			    $RecordCount = $FileSize / $FirstLine.Length
			    # File length should be exactly divisible by the record length, giving a record count to be returned.
			    If ($RecordCount -ne 0) {
				    #-3 Not Fixed Length (when it should be)
				    Write-Host "[$(get-date -format "HH:mm:ss")] Not A Fixed Length File"
				    Return (-3)
			    }

			    Return $RecordCount
		    }
        }
	}
	else {
		#-1 File Not found
		Write-Host "[$(get-date -format "HH:mm:ss")] File Not found"
		Return (-1)
	}
}

Function Check-Delimiters {
	param
	(
		[String]$FilePath,
		[String]$Delimiter=','
	)
    <# 
        Check that all rows in a file have the same delimiter count.  Complicated by possibility of delimiters in the actual data

    #>
    # Testing Data
    # $FilePath = "\\VALWINLVAPP030\bsbappend$\Jobs\TEST_AREA\KT_20220906\ImportTest.csv" ;  $Delimiter = ","
    # $FilePath = "\\VALWINLVAPP030\bsbappend$\Jobs\TEST_AREA\KT_20220906\ImportTest_CRLF.csv" ;  $Delimiter = ","
    # $TestPath = "\\VALWINLVAPP030\bsbappend$\Jobs\TEST_AREA\KT_20220906\CDATest_TrueVision_Temp.pipe" ;  $Delimiter = ","
    

    # dump the data into an object first 
    if( $(Test-path $FilePath) ) {
    
        $RawData = get-content $FilePath

        # We need a temp delimiter which is different to the actual delimiter and does not exist in the data
        $PossibleDelimiters = '|','#','~','^'
        foreach($TestDelimiter in $PossibleDelimiters) {
            if ($([regex]::matches($RawData, "\$TestDelimiter").count) -eq 0) {
                $TempDelimiter = $TestDelimiter
                break
            }
        }

        if( $TempDelimiter.Length -gt 0) {         
            
            # Get the maximum column count
            $MaxColumns = 0
            foreach($Row in $RawData) {
                $MaxColumns =  $($($([regex]::matches($Row, $Delimiter).count) + 1), $MaxColumns | measure -Maximum).Maximum
            }

            # create a Dummy Header with the max number of columns
            $Header = @()
            For ($i = 1; $i -le $MaxColumns; $i++) {
                $Header += "Col$i"
            }
            
            # there could be CRLF's in the data which impacts the way we read raw data, so need to deal with that next
            # Import-CSV deals with it OK, so can use this to identify where the issues exist           
            $CSVData = import-csv $FilePath -Delimiter ',' -header $Header 
            if($rawdata.count -gt $CSVData.count) {
                
                # loop through each row to fix
                $RevisedRawData = @()
                $RawLine = 0
                $CRLF = [char]13 + [char]10
                Foreach($csvLine in $CSVData) {
                    # convert the CSV object back to text and check for a CRLF
                    $ReFormattedLine = ConvertTo-csv -inputobject $CSVLine -Delimiter $TempDelimiter -NoTypeInformation  |  select-object -skip 1 
                    
                    if($ReFormattedLine.contains($CRLF)) {
                        # add the two partial lines together without the CRLF
                        $RevisedRawData+=$($rawdata[$RawLine].Tostring())+$($rawdata[$RawLine+1].Tostring())
                        $RawLine++                        
                    } else {
                        $RevisedRawData+=$rawdata[$RawLine].ToString()
                    }
                    $RawLine++
                }
                $RawData = $RevisedRawData
            }
    
            # For each row, count delimiters, convert to object, convert back to string using a different delimiter and count any delimiters left
            $LastColumns = -1
            $RowCount = 1
            foreach($Row in $RawData) {
                
                # Count the number of delimiters 
                $RawDelimiters =  $([regex]::matches($Row, $Delimiter).count) 

                # convert to object
                $FormattedRow = ConvertFrom-csv $Row -Delimiter $Delimiter -Header $Header 

                # convert back uding a different delimiter - this convert always includes a header which needs excluding
                $ReFormattedLine = ConvertTo-csv -inputobject $FormattedRow -Delimiter $TempDelimiter -NoTypeInformation |  select-object -skip 1 

                # Count the number of columns 
                $LeftDelimiters= $([regex]::matches($ReFormattedLine, $Delimiter).count) 

                # callculate Columns
                $Result = $RawDelimiters - $Leftdelimiters + 1

                if( $LastColumns  -lt 0 ) {
                    $LastColumns = $Result
                }
                elseif ( $LastColumns -ne $Result) {
                    # found an invalid number of columns
                    $Result = -2
                    break
                }
                $RowCount++
            }
        }
        else {
            # found an invalid number of columns
            $Result = -3
        }
    }   
    else {
        # file not found
        $Result = -4
    }

    return $result
}

function Get-MaxColumns {
# get the maximum number of columns in the data provided 

    Param ( [string[]]$DataToCheck,
            [string]$Delimiter ) 

    $MaxColumns = 0
    foreach($Row in $DataToCheck) {
        # $MaxColumns =  $($($([regex]::matches($Row, $Delimiter).count) + 1), $MaxColumns | measure -Maximum).Maximum
        $Columns = $(Parse-CSV -Inputfeed $Row -Delimiter $Delimiter).FieldCount
        $MaxColumns =  $($Columns, $MaxColumns | measure -Maximum).Maximum
    }

    return $MaxColumns
}

function Create-DummyHeader {
# create a dummy header for the number of columns specified
    Param ( [int]$MaxColumns ) 

    $Header = @()
    For ($i = 1; $i -le $MaxColumns; $i++) {
        $Header += "Col$i"
    }

    return $Header
}

function Parse-CSV {
 Param  ( [string]  $InputFeed, 
          [string]  $Delimiter = "," ,
          [string]  $TextQualifier = '"' )
    
    <#  Parsing delimited strings is more complex than most people realise as you need to consider a huge number of variations
        This line is a partial solution which should only be used with the following caveats
        1) Input strings are expected to follow generally accepted guidelines (delimiters and CRLF can be included if the field is quoted)
        2) This only deals with single supplied lines
        
        It will detect quoted fields and deal with these appropriately whether all, none or some fields are quoted 
        It will parse the string and return the fields parsed
        It will return warning flags if the first and/or last fields are suspected to be partial
            This means that the first field doesn't start with a quote but ends with one, or the last fields starts
            with a quote, but doesn't end with one
    
    #>
    
    $Fields=@()
    $Quote = $TextQualifier

    $PartialStart = $False
    $PartialEnd = $False
    $Working = $InputFeed 

    $Finished = $($Working.length -eq 0)
    $SearchOffset = 0

    while(!$Finished) {
        
        if($Working[0] -eq $Quote) {
            $Search = $Quote + $Delimiter
            $Quoted = $true
        } else {
            $Search = $Delimiter
            $Quoted = $false
        }

        $NextDelimiter = $Working.indexof($Search, $SearchOffset)
        $SearchOffset = 0

        if($NextDelimiter -gt 0) {
            if($Quoted) {
                $Fields += $Working.substring( 1, $NextDelimiter -1)
                $Working = $Working.substring( $NextDelimiter + $NextDelimiter.length + 1, $Working.length - $NextDelimiter - $NextDelimiter.length -1)
            } else {
                $Fields += $Working.substring( 0, $NextDelimiter )
                $Working = $Working.substring( $NextDelimiter + $NextDelimiter.length, $Working.length - $NextDelimiter - $NextDelimiter.length )
            }
        }
        elseif($NextDelimiter -eq 0) {
            if($Quoted) {
                # '","","","","","","'
                # comma is the first character in the data - messy
                # need to skip this first occurrence of the delimiter and search again
                $SearchOffset = 2
            }
            elseif ($Working.Length -gt 1) {
                # add the empty field and carry on
                $Fields += ""
                $Working = $Working.substring( 1, $Working.length - 1 )
            }
            else {
                # Add the empty Field and finish
                $Fields += ""
                $Working = ""
            }
        }
        else {
            # no more delimiters so at then end of the string
            if($Quoted) {
                if( $Working.length -eq 1) {
                    # only character is a quote
                    $Fields += $Working
                    $PartialEnd = $true
                }
                elseif ($Working.substring( $Working.length-1 , 1) -eq $Quote) { 
                    $Fields += $Working.substring( 1, $Working.length -2)
                } else {
                    # partial field found
                    $Fields += $Working
                    $PartialEnd = $true
                }
            } else {
                $Fields += $Working
            }
            $Working = ""
            $Finished = $true
        }

        # Check if we have finished but not detected this (Caused by empty last field)
        if(!$Finished -and ($Working.Length -eq 0)) {
            # Add the empty Field and finish
            $Fields += ""
            $Finished = $true
        }
        # $Working
    }

    # check to see if the first field ended in a quote but wasn't quoted.  This indicates a partial line
    if($Fields[0].length -gt 0) {
        if ($Fields[0].substring( $Fields[0].length -1, 1) -eq $Quote) {
            $PartialStart = $True
        }
    }
    
    $Results = [pscustomobject]@{ Fields = $Fields ; FieldCount = $Fields.count; PartialStart = $PartialStart; PartialEnd = $PartialEnd }

    return $Results
}

Function Test-Parse-CSV {

    $InputFeed=@()
    $CrLf = [char]13+[char]10

    $InputFeed += ',"HCSTC01A","HCSTC01B","HCSTC01C","HCSTC02A","HCSTC02B","HCSTC02C","HCSTC03A","HCSTC03B","HCSTC25A",'
    $InputFeed += 'HCSTC01A,HCSTC01B,HCSTC01C,HCSTC02A,HCSTC02B,HCSTC02C,HCSTC03A,HCSTC03B,HCSTC25A'
    $InputFeed += '"HCSTC01A,HCSTC01B",HCSTC01C,"HCSTC02A","HCSTC02B","HCSTC02C","HCSTC03A","HCSTC03B",HCSTC25A'
    $InputFeed += '"HCSTC01A,HCSTC01B",HC"STC"01C,"HCSTC02A","HCSTC02B","HCSTC02C","HCSTC03A","HCSTC03B",HCSTC25A'
    $InputFeed += '"HCSTC01A","HCSTC01B","HCSTC01C","HCSTC02A","HCSTC02B","HCSTC02C","HCSTC03A","HCSTC03B","HCSTC'
    $InputFeed += 'HCSTC01A","HCSTC01B","HCSTC01C","HCSTC02A","HCSTC02B","HCSTC02C","HCSTC03A","HCSTC03B","HCSTC25A'
    $InputFeed += ',,,,,,'
    $InputFeed += ',"","","","","",'
    $InputFeed += $('HCST<CRLF>C01A","HCSTC01B","HCSTC<CRLF>01C","HCSTC02A","HCSTC02B","HCSTC02C","HCSTC03A","HCSTC03B","HCS<CRLF>TC25A').Replace("<CRLF>",$CRLF)
    $InputFeed += '","","","","","","'
    
    $Delimiter = ","

    foreach ($Test in $InputFeed) {

        $ParseResults = ParseCSV $Test $Delimiter 
        clear-host
        write-host "`n$Test"
        write-host "`nField Count  : $($ParseResults.FieldCount)"
        write-host "Partial Start: $($ParseResults.PartialStart)"
        write-host "Partial End  : $($ParseResults.PartialEnd)`n"

        $i = 1
        foreach($Result in $ParseResults.Fields) {
            write-host $i , $Result
            $i++
        }
        Read-Host "`n`nPress <Enter>)"
    }
}

Function Get-SampleFilename {
    Param ( [string]$InputFile )
    # Test $InputFile = "\\CRLWINLVAPP037\bsbappend$\Jobs\CDA0008563_202209\OutputFiles\CDA0008563_202209_Cobra.bsb.csv"

    $InFile     = $(get-item $InputFile)
    $SamplePath = $(join-path $(Split-Path $InputFile -Parent) "Samples")
    $SampleFile = join-path $SamplePath $($InFile.name.Replace($Infile.Extension, "_Sample$($Infile.Extension)"))

    return [string]$SampleFile
}

Function Check-OutputFile {
    # Check a file (fixed or delimited) to confirm column count, or record length is consistent, if a header is present and if nulls are present
	param
	(
		[String]$FilePath,
		[String]$Delimiter=''
	)

    # Test Data
    # $FilePath='\\VALWINLVAPP030\bsbappend$\Jobs\Processing\PSScripts\Development\OutputFiles\Samples\CDA0008975_Refused_Sample.csv';  $Delimiter = ',' 

    $Filename = $(get-item $FilePath).Name

	if (Test-Path -LiteralPath $FilePath) 
	{
                
        # These are sample files, so can read the entire thing each time		
        $RowCount         = 0
		$Windows_Encoding = [System.Text.Encoding]::GetEncoding("Windows-1252")
		$StreamReader     = New-Object System.IO.StreamReader ($FilePath, $Windows_Encoding, $TRUE)
        $LeftOver         = ""
        $HeaderRecord     = $False
        $ColumnCount      = 0
        $RecordLen        = 0
        $NullsFound       = $False
        [char]$NullChar   = 0

        if($Delimiter.Length -gt 0) {
            $Delimited = $True
        } else {
            $Delimited = $False
        }

        while (!($StreamReader.EndOfStream)) {
			
            $FileData = $StreamReader.ReadLine()

            if( $Delimited ) {
                # Combine any previous data from a partial line
                $FileData   = "$LeftOver$FileData"
                $LeftOver   = ""
                $ParsedData = $(Parse-CSV $FileData $Delimiter)
                
                # Save any partial data for to append to next line
                if ($ParsedData.PartialEnd) {
                    $LeftOver = $FileData
                
                } else {              
                    # We have a full line to check      
                    if($RowCount -eq 0) {
                        if($FileData.ToLower().contains("app1urn")) { 
                            $HeaderRecord = $True
                        }
                        $ColumnCount = $ParsedData.FieldCount
                    # check column count is consistent
                    } elseif ($ParsedData.FieldCount -ne $ColumnCount) {
                        $ColumnCount = -1
                    }
                    if($FileData.Contains($NullChar)) {
                        $NullsFound = $True
                    }
                    $RowCount++
                }
            } else {
                
                # check column count is consistent
                if($RowCount -eq 0) {
                    $RecordLen = $FileData.Length
                } elseif ($FileData.Length -ne $RecordLen) {
                    $RecordLen = -1
                }

                if($FileData.Contains($NullChar)) {
                    $NullsFound = $True
                }
                $RowCount++
            }
        }
            
        $Result = [pscustomobject]@{ Name = $(get-item $FilePath).Name;  HeaderRecord=$(if($HeaderRecord) {"Y"}else{"N"}); ColumnCount=$ColumnCount; RecordLength=$RecordLen; NullsFound=$(if($NullsFound) {"Y"}else{"N"}); Count=$RowCount }
        $StreamReader.Close()
        $StreamReader.Dispose()
    
    } else {
        $Result = "File Missing"
    }
    
    Return $Result
    
} 

Function Check-UniqueID {
    # Check a file (fixed or delimited) to confirm column count, or record length is consistent, if a header is present and if nulls are present
	param
	(
		[String]$FilePath,
		[String]$Delimiter,
        [String]$URNFieldName 
	)

    # Test Data
    #FilePath="\\VALWINLVAPP030\bsbappend$\Jobs\TEST_AREA\ParameterForm\Conversions\CDA0009629\SourceFiles\tv_retro_input_20230619_Sample.csv";  $Delimiter = ',' ;$URNFieldName = "URN"

    clear-host
    write-host "$(Get-Date): Starting"
    
	if (Test-Path -LiteralPath $FilePath) 
	{
        $RowCount         = 0
		$Windows_Encoding = [System.Text.Encoding]::GetEncoding("Windows-1252")
		$StreamReader     = New-Object System.IO.StreamReader ($FilePath, $Windows_Encoding, $TRUE)
        $LeftOver         = ""
        $ColumnCount      = 0
        $RecordLen        = 0
        $NullsFound       = $False
        $UniqueID         = $True
        [char]$NullChar   = 0
        $URN_Hash         = @{}

        if($Delimiter.Length -gt 0) {
            $Delimited = $True
        } else {
            $Delimited = $False
        }

        while (!($StreamReader.EndOfStream)) {
			
            $FileData = $StreamReader.ReadLine()

            if( $Delimited ) {
                # Combine any previous data from a partial line
                $FileData   = "$LeftOver$FileData"
                $LeftOver   = ""
                $ParsedData = $(Parse-CSV $FileData $Delimiter)
                
                # Save any partial data for to append to next line
                if ($ParsedData.PartialEnd) {
                    $LeftOver = $FileData
                
                } else {              
                    # We have a full line to check      
                    if($RowCount -eq 0) {
                        $ColumnCount = $ParsedData.FieldCount
                        # find the Field Number for the URN Check
                        [int]$URNField = 0
                        [boolean]$FoundURN = $false

                        For($URNField=0; $URNField -le $($ParsedData.FieldCount-1); $URNField++) {
                            if ($ParsedData.Fields[$URNField] -eq $URNFieldName) {
                                 $FoundURN = $true
                                 break;
                            }
                        }
                        if(!$FoundURN) {
                            $Result = "URN Field Not Found in Header"
                            write-host
                            write-host "  URN Field Not Found in Header"
                            write-host
                            break;
                        }
                        if($FileData.Contains($NullChar)) {
                            $NullsFound = $True
                        }

                    
                    } else {
                        # check column count is consistent
                        if ($ParsedData.FieldCount -ne $ColumnCount) {
                            $ColumnCount = -1
                        }
                            # Check for Nulls
                        if($FileData.Contains($NullChar)) {
                            $NullsFound = $True
                        }
                            # Check for UniqueID
                        if($UniqueID) {
                            if ($($URN_Hash.ContainsKey($ParsedData.Fields[$URNField]))) {
                                $UniqueID= $False
                            } else {
                                $URN_Hash.Add($ParsedData.Fields[$URNField],"1")
                            }
                        }
                    }
                                        
                    $RowCount++
                    if($($RowCount % 10000) -eq 0) {
                        write-host "$(Get-Date): Processed $RowCount"
                    }
                }
            } else {
                
                # check column count is consistent
                if($RowCount -eq 0) {
                    $RecordLen = $FileData.Length
                } elseif ($FileData.Length -ne $RecordLen) {
                    $RecordLen = -1
                }

                if($FileData.Contains($NullChar)) {
                    $NullsFound = $True
                }
                $RowCount++
            }
        }
            
        $Result = [pscustomobject]@{ Name = $(get-item $FilePath).Name;  HeaderRecord=$(if($HeaderRecord) {"Y"}else{"N"}); ColumnCount=$ColumnCount; RecordLength=$RecordLen; NullsFound=$(if($NullsFound) {"Y"}else{"N"}); Count=$RowCount; UniqueURN=$(if($UniqueID) {"Y"} else{"N"}) }
        $StreamReader.Close()
        $StreamReader.Dispose()

        if($FoundURN) {
            write-Host
            write-Host "  File            : $($Result.Name)"
            write-Host "  Record Count    : $($Result.Count)"
            write-Host "  Field Count     : $(if($($Result.ColumnCount) -lt 0){"Inconsistent"} else {$($Result.ColumnCount)})"
            write-Host "  Nulls Found     : $($Result.NullsFound)"
            write-Host "  URN Field Name  : $URNFieldName"
            write-Host "  Unique URN Field: $($Result.UniqueURN)"
            write-Host
        }
    } else {
        write-host
        write-host " Input File Not Found"
        write-host
        
        $Result = $null
    }
    
    write-host "$(Get-Date): Processing Complete"
    write-host 
    Return $Result
   
} 

function Get-JobID_20240410 {
    [CmdletBinding()]
    param
    (
        [Parameter(Mandatory = $true)]  [String] $JobNumber,
        [Parameter(Mandatory = $true)] [String] $ConnectionString 

    )
    $Query  = "SELECT top 1 JobId FROM [BatchWorkflow].[dbo].[Job] where upper(JobNumber)=upper('$JobNumber') and EndDate is not null order by EndDate desc"
    $JobID = Get-SQLScalar $Query $ConnectionString

    return $JobID
}

function Get-JobID {
    # Sometimes the PP script executes before the Job Table has been updated with an EndDate, so need to be a bit more intelligent
    [CmdletBinding()]
    param
    (
        [Parameter(Mandatory = $true)]  [String] $JobNumber,
        [Parameter(Mandatory = $true)] [String] $ConnectionString 

    )
    $Query  = "SELECT Max(JobId) JobId FROM [BatchWorkflow].[dbo].[Job] where upper(JobNumber)=upper('$JobNumber') and Workflow not in ('Reformat','Trigger') and Status in (0,3)"
    $JobID = Get-SQLScalar $Query $ConnectionString

    return $JobID
}

function Get-CobraSQLConfig {
    [CmdletBinding()]
    param
    (
        [Parameter(Mandatory = $True)] [String] $ConfigItem,
        [Parameter(Mandatory = $True)] [String] $ConnectionString 
    )

    $Query = "exec dbo.up_GetConfigValue $ConfigItem " 

    $ConfigValue = Get-SQLScalar $Query  $ConnectionString

    return $ConfigValue
}

function Get-CobraTextConfig {

    [CmdletBinding()]
    param
    (
        [Parameter(Mandatory = $True)] [String]$ConfigItem,
        [Parameter(Mandatory = $True)] [String]$ConfigFile 
    )
    
    if (Test-Path -Path $ConfigFile)
    {
        $data = Import-Csv -Delimiter "|" -Path $ConfigFile
        $configValue = ($data | Where-Object {$_.ConfigItem -eq $configItem}).ConfigValue
    }
    return $configValue
}

function Get-StatsFile {
    [CmdletBinding()]
    param
    (
        [Parameter(Mandatory = $true)]$JobID,
        [Parameter(Mandatory = $true)][String] $JobNumber,
        [Parameter(Mandatory = $true)][String] $ConfigFolder,
        [Parameter(Mandatory = $true)][String] $DBConnectionString,
        [Parameter(Mandatory = $true)][String] $BWFConnectionString
    )

    <# Testing
        $JobID = 36715
        $JobNumber = 'CDA0010043'
        $StatsOutputFolder = '\\valwinlvapp030\bsbappend$\Jobs\CDA0010043\ConfigFiles'
        
        $DBConnectionString  = Get-CobraTextConfig 'MB21' "\\VALWINLVAPP030\bsbappend$\Jobs\Processing\PSScripts\Configuration\SQLConnectionCobraConfig.txt"
        $BWFConnectionString = Get-CobraTextConfig 'BWFE' "\\VALWINLVAPP030\bsbappend$\Jobs\Processing\PSScripts\Configuration\SQLConnectionCobraConfig.txt"
    #>

    Try {
        $StatsSQLCommand = $(get-content $(join-path $(Get-CobraSQLConfig 'ScriptFolder' $DBConnectionString) 'JobMI.sql')).Replace('<JobId>', $JobID)
        $StatsResults    = Get-SQLDataset $StatsSQLCommand  $BWFConnectionString 
        $StatsFile       = join-path $ConfigFolder "$($JobNumber)_Stats.txt"
        $StatsResults | ConvertTo-Csv -NoTypeInformation -Delimiter "`t" | %{$_ -replace('"', '')} | %{$_.ToString().Trim()} | Select-Object -Skip 1 | Out-File $statsFile -Encoding ascii -Force

        return $true
    }
    catch {
        return $false
    }
}

# TOT 626 - Need to get OutputSubfolderas a parameter
function Get-ReportFiles {
    [CmdletBinding()]
    param
    (
        [Parameter(Mandatory = $true)] [String]  $JobNumber,
        [Parameter(Mandatory = $true)] [String]  $JobFolder,
        [Parameter(Mandatory = $true)] [String]  $OutputSubFolder,
        [Parameter(Mandatory = $true)] [Boolean] $ReportMandatory,
        [Parameter(Mandatory = $false)][int]     $JobId=0,
        [Parameter(Mandatory = $false)][Boolean] $UseBIReport=$false, 
        [Parameter(Mandatory = $true)] [string]  $AuditLog 

    )

<# Test Data

    $JobNumber = "CDA0010043"
    $JobFolder = "\\valwinlvapp030\bsbappend$\Jobs\CDA0010043"
    $ReportMandatory = $False
    $AuditLog  = "\\valwinlvapp030\bsbappend$\Jobs\CDA0010043\LogFiles\PP_Test.log"
    $JobId=0

#>
<#  
    There are now possible different reports generated based on Job Type:
    
        Stats File - Downloaded for all types
        
        BSB - no geports generated
        TV  - a BWF Report downloadable via web services
            - a BI Report created by a BI process and passed back via DTP
        DataDNA - a BWF Report downloadable via web services

    All reports will be stored in the OutputFiles folder using the structure below:
        
        OutputFiles\Reports\BWF_Reports\<JobID>\
        OutputFiles\Reports\BI_Reports\<JobID>\

    Only one report will be included in the jobs Output:
    
        For TrueVision Adhoc the BI Report will then be included in the Job Output
        For TrueVision Repeat Jobs the BWF report will be included in the Job Output
        For Data DNA Jobs the BWF report will be included in the Job Output
#>

    Write-Log $AuditLog "Checking for Reports"

    if($JobID -gt 0){
        Write-Log $AuditLog "Overriding JobId - using $JobID"
    }
                
    # Get the data and set all the variables we need
    $ConfigFile           = "\\VALWINLVAPP030\bsbappend$\Jobs\Processing\PSScripts\Configuration\SQLConnectionCobraConfig.txt"
    $ConBWFE              = Get-CobraTextConfig 'BWFE' $ConfigFile
    $ConMB21              = Get-CobraTextConfig 'MB21' $ConfigFile
    $RepeatJob            = If($($JobNumber.Contains('_'))){$True} else {$False}
    
    Write-Log $AuditLog "JobNUmber: $JobNumber - JobID: $JobId - Connection: $ConBWFE"    
    
    $JobType              = Get-SQLScalar "select case when j.Workflow like 'Data%' then 'DNA' else p.[Value] end JobType from [dbo].[Job] j inner join [dbo].[JobProperty] p on j.JobId = p.JobId and p.[Name] = 'Product name' where j.JobId = $JobID" $ConBWFE
    $ConfigFolder         = join-path $JobFolder 'ConfigFiles'
    $JobOutputFolder      = join-path $JobFolder $OutputSubFolder
    $ReportsFolder        = join-path $JobOutputFolder 'Reports'
    $OutputBIReport       = if($JobType -eq "TrueVision") {if($UseBIReport -or !$RepeatJob) { $True } else {$False}} else {$False}
    $DTP_MaxRetries       = Get-CobraSQLConfig "Report_MaxRetries"     $ConMB21
    $DTP_SecondsToDelay   = Get-CobraSQLConfig "Report_SecondsToDelay" $ConMB21
    $DTP_RootFolder       = Get-CobraSQLConfig "Report_BaseFolder"     $ConMB21

    Write-Log $AuditLog "JobId: $JobID - JobType: $JobType"    
    if ($JobID -eq 0) {
        Write-Log $AuditLog "No JobId found for $JobNumber"    
        return ($False)
    }
        
    Create-Folder $JobOutputFolder $AuditLog |out-null
    Create-Folder $ReportsFolder   $AuditLog |out-null

    # Deal with manually downloaded BWF Report files
    $BWF_Name        = $($JobNumber + '_ClientMI.pdf') 
    $BWF_Folder      = join-path $ReportsFolder "BWF_Reports"
    $BWF_FolderFinal = join-path $BWF_Folder    $JobID

    Create-Folder $BWF_Folder      $AuditLog |out-null
    Create-Folder $BWF_FolderFinal $AuditLog |out-null

    if($(test-path $(join-path $JobOutputFolder $BWF_Name))) {
            
        # Need a copy of the report putting in the revised folder structure
        if ($OutputBIReport) {
            # Needs moving out as the BI report will be used
            Move-Item $(join-path $JobOutputFolder $BWF_Name) -Destination $BWF_FolderFinal -force |out-null
            Write-Log $AuditLog "BWF Report Moved to Subfolder"
        }
        else {
            Copy-Item $(join-path $JobOutputFolder $BWF_Name) -Destination $BWF_FolderFinal -force |out-null
            Write-Log $AuditLog "BWF Report Copied to Subfolder"
        }
    }
    elseif($(test-path $(join-path $BWF_FolderFinal $BWF_Name))) {
        Write-Log $AuditLog "BWF Report Already exists in Subfolder"
    }
    #elseif($ReportMandatory) {
    #    Write-Log $AuditLog "BWF Report Download required before executing Post Processing"    
    #    return ($False)
    #}
    
    # CBC 072a - Permissions made available so made live
    Try {    
        
        $BWF_File              = join-path $BWF_FolderFinal $BWF_Name   
        $BWF_URL               = $(if($JobType -eq 'DNA'){$(Get-CobraSQLConfig 'urlDNA' $ConMB21)}elseif($JobType -eq 'TrueVision') {$(Get-CobraSQLConfig 'urlTV' $ConMB21)} else {''}).Replace('{JobId}', $JobID) 
                
        if($BWF_URL.length -gt 0) {

            $BWF_URL = $BWF_URL+'&rs:Format=PDF'

            # Remove BWF report if it already exists
            if(Test-Path $BWF_File) { Remove-Item $BWF_File }

            # Download the BWF Report
            Write-Log $AuditLog "Starting DownLoad of BWF Report"
            Invoke-WebRequest -Uri $BWF_URL -OutFile $BWF_File -UseDefaultCredentials -TimeoutSec 240 |out-null
            Write-Log $AuditLog "Completed DownLoad of BWF Report"
    
            # If this report is to be the output report then copy to the Output location
            if(!$OutputBIReport) {
                Write-Log $AuditLog "Copying BWF Report to OutputFiles folder"
                Copy-Item $BWF_File -Destination $JobOutputFolder -force |out-null
                Write-Log $AuditLog "BWF Report Copied"
            }
        }
        else {
            Write-Log $AuditLog "Unable to establish Report URL"
        }

    }
    Catch {
        Write-Log $AuditLog "Unable to Download BWF Report"
    }

    # BI Reports
    if ($JobType -eq 'TrueVision') {
            
        # Setup Variables for this part 
        $DTP_JobFolder       = join-path $DTP_RootFolder $JobNumber
        $DTP_FileName        = $($JobNumber + '_TrueVision_ClientMI.pdf') 
        $DTP_File            = join-path $(join-path $DTP_JobFolder $JobId) $DTP_FileName

        $BI_Folder           = join-path $ReportsFolder "BI_Reports"
        Create-Folder $BI_Folder $AuditLog |out-null

        #First need to know if the BI Report has previously been copied to the Reports Subfolder
        $TargetBIReport = $(join-path $(join-path $BI_Folder $JobID) $DTP_FileName)

        # If already copied we don't need to wait for it
        if($(test-path $TargetBIReport)) {
            $WaitingForFile  = $False
            $FoundFile       = $True
            Write-Log $AuditLog "BI Report already Copied"
        } else {
            $WaitingForFile  = $True
            $FoundFile       = $False
            Write-Log $AuditLog "Waiting for BI Report"
        }    
                
        $DTP_Retries  = 0
        while($WaitingForFile) {
            if ($(Test-path $DTP_File)) {
                $WaitingForFile = $False
                $FoundFile      = $True
                Write-Log $AuditLog "BI Report Found"
            }
            elseif ($DTP_Retries -gt $DTP_MaxRetries ) { 
                $WaitingForFile = $False
                Write-Log $AuditLog "BI Report NOT Found"
            }
            else{
                $DTP_Retries++
                Start-Sleep -Seconds $DTP_SecondsToDelay
            }
        }
        
        if ($FoundFile) {
            # Now we know the main file is there we can loop though and copy all the reports we find for this job
            $DTP_FolderList = get-childitem $DTP_JobFolder -Directory
            foreach($DTP_ReportFolder in $DTP_FolderList) {
                $DTP_ThisReport = $(join-path $DTP_ReportFolder.FullName $DTP_FileName)
                if(test-path $DTP_ThisReport) {
                
                    $BI_TargetFolder = join-path $BI_Folder $($DTP_ReportFolder.Name)
                    Create-Folder $BI_TargetFolder $AuditLog |out-null

                    #$DTP_ThisReport.MoveTo($BI_TargetFolder)
                    Move-Item $DTP_ThisReport -Destination $BI_TargetFolder -force |out-null
                     
                    Remove-Item $DTP_ReportFolder.FullName |out-null
                }
            }

            # If this report is to be the output report then copy to the Output location
            if($OutputBIReport) {
                Write-Log $AuditLog "Copying latest BI Report to OutputFiles folder"
                
                $BI_Report = join-path $(join-path $BI_Folder $JobId) $DTP_FileName
                Copy-Item $BI_Report -Destination $JobOutputFolder -force |out-null

                Write-Log $AuditLog "BI Report Copied"
            }
        }
    }
    else {
        #DNA Job
        $Foundfile = $True
    }

    if($Foundfile) {
        Write-Log $AuditLog "Report Check Complete"
    } else {
        Write-Log $AuditLog "Report Check Failed"
    }

    return ($Foundfile)

}

# TOT 615 New Function Added
function Get-FixedLengthRowCount {
    param
    (
        [Parameter(Mandatory = $true)] [String]  $FilePath
    )
    # $FilePath ="\\VALWINLVAPP030\bsbappend$\Jobs\TEST_AREA\CDA100895_202401\OutputFiles\CDA100895_202401_14_Cobra.bsb_WithHeader.OutputCheck"

    # Divide file size by first line length to determine row count
    $FileSize = $(get-item $FilePath).length

    # add 2 to row length for theCRLF which are dropped when reading
    $RowLength = $(get-content $FilePath -first 1).Length + 2

    # verify
    if( ($FileSize % $RowLength) -eq 0) {
        $RowCount = $FileSize / $RowLength
    }
    else {
        $RowCount = -1
    }
    
    return $RowCount
}


